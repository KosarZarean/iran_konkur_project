"""
Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†Ú©ÙˆØ± Ø§ÛŒØ±Ø§Ù†
"""

import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings
warnings.filterwarnings('ignore')


class ExamDataManager:
    """
    Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†Ú©ÙˆØ±
    """
    
    def __init__(self, data_dir='data', recording_file='analysis.txt', plots_folder='plots'):
        self.data_dir = data_dir
        self.recording_file = recording_file
        self.plots_folder = plots_folder
        
        os.makedirs(data_dir, exist_ok=True)
        os.makedirs(plots_folder, exist_ok=True)
        
        self.df = None
        self.X = None
        self.y = None
        self.num_classes = None
        self.target_col = None
        self.task_type = None
        
        # For TabTransformer
        self.categories = None
        self.continuous_features = 0
        self.X_cat = None
        self.X_cont = None
        
        # For splits
        self.train_indices = None
        self.val_indices = None
        self.test_indices = None
        
        # Preprocessing objects
        self.scaler = StandardScaler()
        self.label_encoders = {}
        
        print(f"ğŸ“ Ù…Ø¯ÛŒØ± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
    
    def load_and_prepare_data(self, data_path=None, task_type='regression'):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        print("\nğŸ“ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†Ú©ÙˆØ±...")
        
        self.task_type = task_type
        
        if data_path is None:
            data_path = self._find_exam_data()
        
        self._load_exam_data(data_path)
        self._clean_data()
        self._define_task()
        
        print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯: {len(self.df)} Ù†Ù…ÙˆÙ†Ù‡")
        return self.df
    
    def _find_exam_data(self):
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡"""
        possible_paths = [
            'iran_exam.csv',
            'data/iran_exam.csv',
            '/content/iran_exam.csv',
            '../data/iran_exam.csv'
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                print(f"ğŸ“ ÛŒØ§ÙØªÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø±: {path}")
                return path
        
        raise FileNotFoundError("âŒ ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†Ú©ÙˆØ± ÛŒØ§ÙØª Ù†Ø´Ø¯")
    
    def _load_exam_data(self, data_path):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ CSV"""
        try:
            self.df = pd.read_csv(data_path)
            print(f"ğŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù†Ø¯. Ø´Ú©Ù„: {self.df.shape}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
            raise
    
    def _clean_data(self):
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        print("\nğŸ§¹ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
        
        # Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡
        missing_before = self.df.isnull().sum().sum()
        if missing_before > 0:
            print(f"  ğŸ” Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡: {missing_before}")
            
            numeric_cols = self.df.select_dtypes(include=['int64', 'float64']).columns
            for col in numeric_cols:
                if self.df[col].isnull().sum() > 0:
                    self.df[col].fillna(self.df[col].median(), inplace=True)
            
            categorical_cols = self.df.select_dtypes(include=['object']).columns
            for col in categorical_cols:
                if self.df[col].isnull().sum() > 0:
                    mode_val = self.df[col].mode()[0] if len(self.df[col].mode()) > 0 else 'Ù†Ø§Ù…Ø´Ø®Øµ'
                    self.df[col].fillna(mode_val, inplace=True)
        
        # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ù…Ù†Ø·Ù‚Ù‡
        if 'Ù…Ù†Ø·Ù‚Ù‡' in self.df.columns:
            region_map = {
                'Ù…Ù†Ø·Ù‚Ù‡1': 'Ù…Ù†Ø·Ù‚Ù‡1', 'Ù…Ù†Ø·Ù‚Ù‡ÙŠÚ©': 'Ù…Ù†Ø·Ù‚Ù‡1', 'Ù…Ù†Ø·Ù‚Ù‡ÛŒÚ©': 'Ù…Ù†Ø·Ù‚Ù‡1',
                'Ù…Ù†Ø·Ù‚Ù‡2': 'Ù…Ù†Ø·Ù‚Ù‡2', 'Ù…Ù†Ø·Ù‚Ù‡Ø¯Ùˆ': 'Ù…Ù†Ø·Ù‚Ù‡2',
                'Ù…Ù†Ø·Ù‚Ù‡3': 'Ù…Ù†Ø·Ù‚Ù‡3', 'Ù…Ù†Ø·Ù‚Ù‡Ø³Ù‡': 'Ù…Ù†Ø·Ù‚Ù‡3'
            }
            self.df['Ù…Ù†Ø·Ù‚Ù‡'] = self.df['Ù…Ù†Ø·Ù‚Ù‡'].apply(
                lambda x: region_map.get(str(x).strip(), str(x).strip())
            )
        
        print("âœ… Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
    
    def _define_task(self):
        """ØªØ¹Ø±ÛŒÙ ÙˆØ¸ÛŒÙÙ‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
        print(f"\nğŸ¯ ØªØ¹Ø±ÛŒÙ ÙˆØ¸ÛŒÙÙ‡: {self.task_type}")
        
        if self.task_type == 'classification':
            if 'Ø±ØªØ¨Ù‡ Ú©Ø´ÙˆØ±ÛŒ' in self.df.columns:
                threshold = self.df['Ø±ØªØ¨Ù‡ Ú©Ø´ÙˆØ±ÛŒ'].quantile(0.2)
                self.df['target'] = (self.df['Ø±ØªØ¨Ù‡ Ú©Ø´ÙˆØ±ÛŒ'] <= threshold).astype(int)
                self.target_col = 'target'
                print(f"  Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ: Ø¢Ø³ØªØ§Ù†Ù‡ Ø±ØªØ¨Ù‡ â‰¤ {threshold:.0f}")
        else:
            if 'Ø±ØªØ¨Ù‡ Ú©Ø´ÙˆØ±ÛŒ' in self.df.columns:
                self.target_col = 'Ø±ØªØ¨Ù‡ Ú©Ø´ÙˆØ±ÛŒ'
                print(f"  Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ØªØ¨Ù‡ Ú©Ø´ÙˆØ±ÛŒ")
    
    def prepare_for_traditional_models(self):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†ØªÛŒ"""
        print("\nğŸ”„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†ØªÛŒ...")
        
        feature_cols = [col for col in self.df.columns if col != self.target_col]
        categorical_cols = self.df.select_dtypes(include=['object']).columns
        categorical_cols = [col for col in categorical_cols if col in feature_cols]
        
        X_list = []
        numerical_cols = [col for col in feature_cols if col not in categorical_cols]
        
        if numerical_cols:
            X_numerical = self.df[numerical_cols].values
            X_numerical = self.scaler.fit_transform(X_numerical)
            X_list.append(X_numerical)
        
        if categorical_cols:
            X_categorical_list = []
            for col in categorical_cols:
                le = LabelEncoder()
                encoded = le.fit_transform(self.df[col].astype(str))
                X_categorical_list.append(encoded.reshape(-1, 1))
                self.label_encoders[col] = le
            
            X_categorical = np.hstack(X_categorical_list)
            X_list.append(X_categorical)
        
        if len(X_list) > 1:
            self.X = np.hstack(X_list)
        else:
            self.X = X_list[0]
        
        self.y = self.df[self.target_col].values
        print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯: X shape: {self.X.shape}")
        return self.X, self.y
    
    def prepare_for_tabtransformer(self):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ TabTransformer"""
        print("\nğŸ”„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ TabTransformer...")
        
        categorical_cols = self.df.select_dtypes(include=['object']).columns
        numerical_cols = [col for col in self.df.columns 
                         if col not in categorical_cols and col != self.target_col]
        
        if len(categorical_cols) > 0:
            X_cat_list = []
            self.categories = []
            
            for col in categorical_cols:
                le = LabelEncoder()
                encoded = le.fit_transform(self.df[col].astype(str))
                X_cat_list.append(encoded.reshape(-1, 1))
                self.categories.append(len(le.classes_))
                self.label_encoders[col] = le
            
            self.X_cat = np.hstack(X_cat_list).astype(np.int64)
        else:
            self.X_cat = np.zeros((len(self.df), 0), dtype=np.int64)
            self.categories = []
        
        if len(numerical_cols) > 0:
            X_cont = self.df[numerical_cols].values.astype(np.float32)
            self.X_cont = self.scaler.fit_transform(X_cont)
            self.continuous_features = len(numerical_cols)
        else:
            self.X_cont = np.zeros((len(self.df), 0), dtype=np.float32)
            self.continuous_features = 0
        
        self.y = self.df[self.target_col].values
        
        print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ TabTransformer Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯")
        return self.X_cat, self.X_cont, self.y
    
    def create_train_val_test_split(self, train_size=0.7, val_size=0.15, test_size=0.15):
        """ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        print(f"\nâœ‚ï¸ Ø§ÛŒØ¬Ø§Ø¯ ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
        
        X_train, X_temp, y_train, y_temp, idx_train, idx_temp = train_test_split(
            self.X, self.y, np.arange(len(self.X)),
            test_size=(val_size + test_size),
            random_state=42,
            stratify=self.y if self.task_type == 'classification' else None
        )
        
        val_ratio = val_size / (val_size + test_size)
        X_val, X_test, y_val, y_test, idx_val, idx_test = train_test_split(
            X_temp, y_temp, idx_temp,
            test_size=test_size/(val_size+test_size),
            random_state=42,
            stratify=y_temp if self.task_type == 'classification' else None
        )
        
        self.train_indices = idx_train
        self.val_indices = idx_val
        self.test_indices = idx_test
        
        self.X_train, self.y_train = X_train, y_train
        self.X_val, self.y_val = X_val, y_val
        self.X_test, self.y_test = X_test, y_test
        
        print(f"âœ… Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
        return (X_train, y_train), (X_val, y_val), (X_test, y_test)
