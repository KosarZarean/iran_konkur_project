"""
Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†Ú©ÙˆØ± Ø§ÛŒØ±Ø§Ù†
Ø´Ø§Ù…Ù„: Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒØŒ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…ØŒ Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒØŒ XGBoostØŒ LightGBMØŒ MLP Ùˆ ...
"""

import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
# âŒ Ø®Ø· CatBoost Ø­Ø°Ù Ø´Ø¯
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')


class BaselineModels:
    """
    Ú©Ù„Ø§Ø³ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
    Ø´Ø§Ù…Ù„ Û±Û´ Ù…Ø¯Ù„ Ù…Ø®ØªÙ„Ù Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†
    """
    
    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, task_type='regression'):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Ù‡
        """
        self.X_train = X_train
        self.y_train = y_train
        self.X_val = X_val
        self.y_val = y_val
        self.X_test = X_test
        self.y_test = y_test
        self.task_type = task_type
        
        self.models = {}
        self.results = []
        self.predictions = {}
        self.training_times = {}
        
        print(f"ğŸ“Š BaselineModels Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
        print(f"   Ø¢Ù…ÙˆØ²Ø´: {X_train.shape[0]} Ù†Ù…ÙˆÙ†Ù‡")
        print(f"   Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {X_val.shape[0]} Ù†Ù…ÙˆÙ†Ù‡")
        print(f"   Ø¢Ø²Ù…Ø§ÛŒØ´: {X_test.shape[0]} Ù†Ù…ÙˆÙ†Ù‡")
    
    def define_models(self):
        """
        ØªØ¹Ø±ÛŒÙ Û±Û´ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ù…Ø®ØªÙ„Ù (Ø¨Ø¯ÙˆÙ† CatBoost)
        """
        print("\nğŸ“‹ ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡...")
        
        self.models = {
            # 1. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø·ÛŒ
            'Linear Regression': LinearRegression(),
            'Ridge Regression': Ridge(alpha=1.0, random_state=42),
            'Lasso Regression': Lasso(alpha=0.1, random_state=42),
            'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),
            
            # 2. Ø¯Ø±Ø®Øªâ€ŒÙ‡Ø§
            'Decision Tree': DecisionTreeRegressor(max_depth=10, min_samples_split=5, random_state=42),
            'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=5, 
                                                  n_jobs=-1, random_state=42),
            'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, 
                                                          max_depth=5, random_state=42),
            'AdaBoost': AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42),
            
            # 3. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† Ù‡Ù…Ø³Ø§ÛŒÙ‡
            'KNN': KNeighborsRegressor(n_neighbors=5, weights='distance', n_jobs=-1),
            
            # 4. Ù…Ø§Ø´ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø± Ù¾Ø´ØªÛŒØ¨Ø§Ù†
            'SVR (linear)': SVR(kernel='linear', C=1.0),
            'SVR (rbf)': SVR(kernel='rbf', C=100, gamma=0.1),
            
            # 5. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
            'XGBoost': XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1,
                                    subsample=0.8, colsample_bytree=0.8, random_state=42, verbosity=0),
            'LightGBM': LGBMRegressor(n_estimators=100, max_depth=6, learning_rate=0.1,
                                     num_leaves=31, random_state=42, verbose=-1),
            # âŒ CatBoost Ø­Ø°Ù Ø´Ø¯
            
            # 6. Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ
            'MLP': MLPRegressor(hidden_layer_sizes=(128, 64, 32), activation='relu',
                               solver='adam', max_iter=500, random_state=42)
        }
        
        print(f"âœ… {len(self.models)} Ù…Ø¯Ù„ ØªØ¹Ø±ÛŒÙ Ø´Ø¯")
        
        # Ù†Ù…Ø§ÛŒØ´ Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§
        for i, (name, _) in enumerate(self.models.items(), 1):
            print(f"   {i:2d}. {name}")
    
    def train_and_evaluate(self, verbose=True):
        """Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        print("\n" + "="*80)
        print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡")
        print("="*80)
        
        for name, model in self.models.items():
            if verbose:
                print(f"\nğŸ“ˆ Ø¢Ù…ÙˆØ²Ø´ {name}...")
            
            start_time = time.time()
            
            try:
                # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
                model.fit(self.X_train, self.y_train)
                
                # Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´
                training_time = time.time() - start_time
                self.training_times[name] = training_time
                
                # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
                y_pred_train = model.predict(self.X_train)
                y_pred_val = model.predict(self.X_val)
                y_pred_test = model.predict(self.X_test)
                
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
                result = {
                    'Model': name,
                    'Train RMSE': np.sqrt(mean_squared_error(self.y_train, y_pred_train)),
                    'Val RMSE': np.sqrt(mean_squared_error(self.y_val, y_pred_val)),
                    'Test RMSE': np.sqrt(mean_squared_error(self.y_test, y_pred_test)),
                    'Train MAE': mean_absolute_error(self.y_train, y_pred_train),
                    'Val MAE': mean_absolute_error(self.y_val, y_pred_val),
                    'Test MAE': mean_absolute_error(self.y_test, y_pred_test),
                    'Train R2': r2_score(self.y_train, y_pred_train),
                    'Val R2': r2_score(self.y_val, y_pred_val),
                    'Test R2': r2_score(self.y_test, y_pred_test),
                    'Time (s)': training_time
                }
                
                self.results.append(result)
                self.predictions[name] = y_pred_test
                
                if verbose:
                    print(f"   âœ… Test RMSE: {result['Test RMSE']:.2f}, RÂ²: {result['Test R2']:.4f}, Ø²Ù…Ø§Ù†: {training_time:.2f}s")
                
            except Exception as e:
                if verbose:
                    print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ {name}: {e}")
        
        # Ø§ÛŒØ¬Ø§Ø¯ DataFrame Ù†ØªØ§ÛŒØ¬
        results_df = pd.DataFrame(self.results)
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ RMSE
        if not results_df.empty:
            results_df = results_df.sort_values('Test RMSE')
        
        print("\n" + "="*80)
        print("âœ… Ø¢Ù…ÙˆØ²Ø´ Ù‡Ù…Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯")
        print("="*80)
        
        return results_df
    
    def get_best_model(self, metric='Test RMSE'):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø± Ù…Ø´Ø®Øµ"""
        if not self.results:
            return None, None
        
        df = pd.DataFrame(self.results)
        
        if metric == 'Test R2':
            best_idx = df[metric].argmax()
            best_value = df[metric].max()
        else:
            best_idx = df[metric].argmin()
            best_value = df[metric].min()
        
        best_model = df.iloc[best_idx]['Model']
        
        return best_model, best_value
    
    def plot_comparison(self, metric='Test RMSE', save_path='plots/baseline_comparison.jpg'):
        """Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
        if not self.results:
            print("âŒ Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return
        
        df = pd.DataFrame(self.results)
        df = df.sort_values(metric)
        
        # Ø§Ù†ØªØ®Ø§Ø¨ Û±Û° Ù…Ø¯Ù„ Ø¨Ø±ØªØ±
        top_models = df.head(10)
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. RMSE Ù…Ù‚Ø§ÛŒØ³Ù‡
        axes[0, 0].barh(top_models['Model'], top_models['Test RMSE'], 
                       color='skyblue', edgecolor='black')
        axes[0, 0].set_xlabel('RMSE (lower is better)')
        axes[0, 0].set_title('Top 10 Models - RMSE Comparison')
        axes[0, 0].grid(True, alpha=0.3, axis='x')
        
        # 2. RÂ² Ù…Ù‚Ø§ÛŒØ³Ù‡
        axes[0, 1].barh(top_models['Model'], top_models['Test R2'], 
                       color='lightgreen', edgecolor='black')
        axes[0, 1].set_xlabel('RÂ² (higher is better)')
        axes[0, 1].set_title('Top 10 Models - RÂ² Comparison')
        axes[0, 1].grid(True, alpha=0.3, axis='x')
        axes[0, 1].axvline(x=0, color='red', linestyle='--', alpha=0.5)
        
        # 3. Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´
        axes[1, 0].barh(top_models['Model'], top_models['Time (s)'], 
                       color='salmon', edgecolor='black')
        axes[1, 0].set_xlabel('Training Time (seconds)')
        axes[1, 0].set_title('Training Time Comparison')
        axes[1, 0].grid(True, alpha=0.3, axis='x')
        
        # 4. Train vs Test RMSE
        x = np.arange(len(top_models))
        width = 0.35
        
        axes[1, 1].bar(x - width/2, top_models['Train RMSE'], width, 
                      label='Train RMSE', color='skyblue', edgecolor='black')
        axes[1, 1].bar(x + width/2, top_models['Test RMSE'], width,
                      label='Test RMSE', color='lightcoral', edgecolor='black')
        axes[1, 1].set_xlabel('Model')
        axes[1, 1].set_ylabel('RMSE')
        axes[1, 1].set_title('Train vs Test RMSE')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(top_models['Model'], rotation=45, ha='right')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.suptitle('Baseline Models Comparison', fontsize=16, y=1.02)
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø± {save_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    
    def generate_report(self, save_path='reports/baseline_report.txt'):
        """Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø§Ø² Ù†ØªØ§ÛŒØ¬"""
        if not self.results:
            print("âŒ Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return
        
        df = pd.DataFrame(self.results)
        best_model, best_rmse = self.get_best_model('Test RMSE')
        best_r2_model, best_r2 = self.get_best_model('Test R2')
        
        report = []
        report.append("="*80)
        report.append("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡")
        report.append("="*80)
        report.append(f"ØªØ§Ø±ÛŒØ®: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡
        report.append("ğŸ“‹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡:")
        report.append(f"   ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: {len(self.X_train)}")
        report.append(f"   ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {len(self.X_val)}")
        report.append(f"   ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…Ø§ÛŒØ´: {len(self.X_test)}")
        report.append(f"   ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: {self.X_train.shape[1]}")
        report.append("")
        
        # Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§
        report.append("ğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§:")
        report.append(f"   Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ RMSE: {best_model} (RMSE={best_rmse:.2f})")
        report.append(f"   Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ RÂ²: {best_r2_model} (RÂ²={best_r2:.4f})")
        report.append("")
        
        # Û±Û° Ù…Ø¯Ù„ Ø¨Ø±ØªØ±
        report.append("ğŸ“Š Û±Û° Ù…Ø¯Ù„ Ø¨Ø±ØªØ± (Ø¨Ø± Ø§Ø³Ø§Ø³ RMSE):")
        report.append("-" * 80)
        top10 = df.nsmallest(10, 'Test RMSE')[['Model', 'Test RMSE', 'Test R2', 'Test MAE', 'Time (s)']]
        
        for _, row in top10.iterrows():
            report.append(f"   {row['Model']:25s} | RMSE={row['Test RMSE']:8.2f} | RÂ²={row['Test R2']:.4f} | MAE={row['Test MAE']:7.2f} | Ø²Ù…Ø§Ù†={row['Time (s)']:.2f}s")
        
        report.append("")
        report.append("="*80)
        report.append("âœ… Ù¾Ø§ÛŒØ§Ù† Ú¯Ø²Ø§Ø±Ø´")
        report.append("="*80)
        
        report_text = "\n".join(report)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(f"ğŸ“ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± {save_path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        
        return report_text
    
    def save_results(self, path='results/baseline_results.csv'):
        """Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± ÙØ§ÛŒÙ„ CSV"""
        if not self.results:
            print("âŒ Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return
        
        df = pd.DataFrame(self.results)
        df = df.sort_values('Test RMSE')
        
        os.makedirs(os.path.dirname(path), exist_ok=True)
        df.to_csv(path, index=False, encoding='utf-8-sig')
        
        print(f"ğŸ’¾ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± {path} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        
        return df
