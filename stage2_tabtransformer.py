#!/usr/bin/env python3
"""
Ù…Ø±Ø­Ù„Ù‡ Û²: TabTransformer
Ø±ÙØ¹ Ø´Ø¯Ù‡ - Ù…Ø´Ú©Ù„ None Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø·Ø±Ù Ø´Ø¯Ù‡
"""

import os
import sys
import numpy as np
import pandas as pd
import torch
from datetime import datetime

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± src
sys.path.append('src')

from exam_data_manager import ExamDataManager
from exam_models import TabTransformer
from exam_trainer import ExamTrainer


def run_stage2(data_path='data/iran_exam.csv'):
    print("\n" + "="*70)
    print("ğŸ¯ Ù…Ø±Ø­Ù„Ù‡ Û²: TabTransformer")
    print("="*70)
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
    os.makedirs('results/stage2', exist_ok=True)
    os.makedirs('plots/stage2', exist_ok=True)
    os.makedirs('models/stage2', exist_ok=True)
    os.makedirs('reports', exist_ok=True)
    
    # ============================================
    # Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
    # ============================================
    print("\nğŸ“Š Ù…Ø±Ø­Ù„Ù‡ Û²-Û±: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    data_manager = ExamDataManager()
    df = data_manager.load_and_prepare_data(data_path, 'regression')
    
    # ============================================
    # Û². Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ TabTransformer
    # ============================================
    print("\nğŸ”„ Ù…Ø±Ø­Ù„Ù‡ Û²-Û²: Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ TabTransformer...")
    X_cat, X_cont, y = data_manager.prepare_for_tabtransformer()
    
    print(f"\n   âœ… X_cat shape: {X_cat.shape}")
    print(f"   âœ… X_cont shape: {X_cont.shape}")
    print(f"   âœ… y shape: {y.shape}")
    
    # ============================================
    # Û³. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ (Ø¨Ø§ Ù†Ù…ÙˆÙ†Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹)
    # ============================================
    print("\nâœ‚ï¸ Ù…Ø±Ø­Ù„Ù‡ Û²-Û³: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    
    # Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹ØŒ ÙÙ‚Ø· Û±Û°Û°Û°Û° Ù†Ù…ÙˆÙ†Ù‡ Ø§ÙˆÙ„ Ø±Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    n_samples = min(10000, len(y))
    indices = np.random.permutation(n_samples)
    
    n_train = int(n_samples * 0.7)
    n_val = int(n_samples * 0.15)
    
    train_idx = indices[:n_train]
    val_idx = indices[n_train:n_train + n_val]
    test_idx = indices[n_train + n_val:]
    
    print(f"   - Ø¢Ù…ÙˆØ²Ø´: {len(train_idx)} Ù†Ù…ÙˆÙ†Ù‡")
    print(f"   - Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {len(val_idx)} Ù†Ù…ÙˆÙ†Ù‡")
    print(f"   - Ø¢Ø²Ù…Ø§ÛŒØ´: {len(test_idx)} Ù†Ù…ÙˆÙ†Ù‡")
    
    # ============================================
    # Û´. Ø³Ø§Ø®Øª Ù…Ø¯Ù„
    # ============================================
    print("\nğŸ—ï¸ Ù…Ø±Ø­Ù„Ù‡ Û²-Û´: Ø³Ø§Ø®Øª Ù…Ø¹Ù…Ø§Ø±ÛŒ TabTransformer...")
    model = TabTransformer(
        num_categorical=X_cat.shape[1],
        num_continuous=X_cont.shape[1],
        categories=data_manager.categories,
        embedding_dim=32,
        num_heads=4,
        num_layers=3,
        mlp_hidden_dims=[128, 64],
        mlp_dropout=0.2,
        transformer_dropout=0.1,
        output_dim=1
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"   âœ… ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
    
    # ============================================
    # Ûµ. Ø§ÛŒØ¬Ø§Ø¯ DataLoader (Ø±ÙØ¹ Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ)
    # ============================================
    print("\nğŸ“¦ Ù…Ø±Ø­Ù„Ù‡ Û²-Ûµ: Ø§ÛŒØ¬Ø§Ø¯ DataLoader...")
    
    trainer = ExamTrainer(model, model_type='tabtransformer', model_name='tabtransformer')
    
    # Ø§Ø±Ø³Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ trainer
    trainer.create_dataloaders(
        X_train=None, y_train=None,  # Ø¨Ø±Ø§ÛŒ tabtransformer Ø§ÛŒÙ†Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
        X_val=None, y_val=None,
        X_cat_train=X_cat[train_idx],
        X_cont_train=X_cont[train_idx],
        y_train=y[train_idx],
        X_cat_val=X_cat[val_idx],
        X_cont_val=X_cont[val_idx],
        y_val=y[val_idx],
        batch_size=64
    )
    
    # ============================================
    # Û¶. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    # ============================================
    print("\nğŸš€ Ù…Ø±Ø­Ù„Ù‡ Û²-Û¶: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„...")
    trainer.train(
        epochs=30,  # ØªØ¹Ø¯Ø§Ø¯ Ú©Ù…ØªØ± Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹
        lr=0.001,
        weight_decay=1e-5,
        patience=10,
        verbose=True
    )
    
    # ============================================
    # Û·. Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¢Ù…ÙˆØ²Ø´
    # ============================================
    print("\nğŸ“ˆ Ù…Ø±Ø­Ù„Ù‡ Û²-Û·: Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´...")
    trainer.plot_history('plots/stage2/training_history.jpg')
    
    # ============================================
    # Û¸. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
    # ============================================
    print("\nğŸ§ª Ù…Ø±Ø­Ù„Ù‡ Û²-Û¸: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„...")
    results = trainer.evaluate(
        X_test=None, y_test=None,  # Ø¨Ø±Ø§ÛŒ tabtransformer
        X_cat_test=X_cat[test_idx],
        X_cont_test=X_cont[test_idx],
        y_test=y[test_idx]
    )
    
    # ============================================
    # Û¹. Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
    # ============================================
    print("\nğŸ’¾ Ù…Ø±Ø­Ù„Ù‡ Û²-Û¹: Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„...")
    trainer.save_model('tabtransformer_model.pt')
    
    # ============================================
    # Û±Û°. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    # ============================================
    results_df = pd.DataFrame([{
        'Model': 'TabTransformer',
        'RMSE': results['rmse'],
        'R2': results['r2']
    }])
    results_df.to_csv('results/stage2/tabtransformer_results.csv', index=False, encoding='utf-8-sig')
    
    # ============================================
    # Û±Û±. Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´
    # ============================================
    report = f"""
{'='*70}
ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø±Ø­Ù„Ù‡ Û²: TabTransformer
{'='*70}
ØªØ§Ø±ÛŒØ®: {datetime.now()}

ğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø§Ø¯Ù‡:
   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: {len(y)}
   Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡: {n_samples}
   ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ: {X_cat.shape[1]}
   ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ: {X_cont.shape[1]}

ğŸ—ï¸ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø¯Ù„:
   embedding_dim: 32
   num_heads: 4
   num_layers: 3
   mlp_hidden: [128, 64]
   dropout: 0.2
   ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}

ğŸ“ˆ Ù†ØªØ§ÛŒØ¬ Ø¢Ù…ÙˆØ²Ø´:
   Ø¨Ù‡ØªØ±ÛŒÙ† RMSE Ø¢Ù…ÙˆØ²Ø´: {min(trainer.history['train_rmse']):.2f}
   Ø¨Ù‡ØªØ±ÛŒÙ† RMSE Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {min(trainer.history['val_rmse']):.2f}

ğŸ¯ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª:
   RMSE: {results['rmse']:.2f}
   RÂ²: {results['r2']:.4f}

ğŸ“ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡:
   - Ù…Ø¯Ù„: models/stage2/tabtransformer_model.pt
   - Ù†ØªØ§ÛŒØ¬: results/stage2/tabtransformer_results.csv
   - Ù†Ù…ÙˆØ¯Ø§Ø±: plots/stage2/training_history.jpg
{'='*70}
"""
    
    with open('reports/stage2_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(report)
    return results, trainer, report


if __name__ == "__main__":
    run_stage2()
