#!/usr/bin/env python3
"""
Ù…Ø±Ø­Ù„Ù‡ Û²: TabTransformer
Ø§Ø¬Ø±Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø®Ø±ÙˆØ¬ÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´
"""

import os
import sys
import numpy as np
import pandas as pd
import torch
from datetime import datetime

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± src
sys.path.append('src')

from exam_data_manager import ExamDataManager
from exam_models import TabTransformer
from exam_trainer import ExamTrainer


def run_stage2(data_path='data/iran_exam.csv'):
    """
    Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡ Û² Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    """
    print("\n" + "="*70)
    print("ğŸ¯ Ù…Ø±Ø­Ù„Ù‡ Û²: TabTransformer")
    print("="*70)
    print(f"ğŸ“… Ø²Ù…Ø§Ù† Ø´Ø±ÙˆØ¹: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*70)
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
    os.makedirs('results/stage2', exist_ok=True)
    os.makedirs('plots/stage2', exist_ok=True)
    os.makedirs('models/stage2', exist_ok=True)
    os.makedirs('reports', exist_ok=True)
    
    # Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
    print("\nğŸ“Š Ù…Ø±Ø­Ù„Ù‡ Û²-Û±: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    data_manager = ExamDataManager()
    df = data_manager.load_and_prepare_data(data_path, 'regression')
    
    # Û². Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ TabTransformer
    print("\nğŸ”„ Ù…Ø±Ø­Ù„Ù‡ Û²-Û²: Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ TabTransformer...")
    X_cat, X_cont, y = data_manager.prepare_for_tabtransformer()
    
    print(f"   X_cat shape: {X_cat.shape}")
    print(f"   X_cont shape: {X_cont.shape}")
    print(f"   categories: {data_manager.categories}")
    
    # Û³. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡
    print("\nâœ‚ï¸ Ù…Ø±Ø­Ù„Ù‡ Û²-Û³: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    n = len(y)
    indices = np.random.permutation(n)
    train_idx = indices[:int(n*0.7)]
    val_idx = indices[int(n*0.7):int(n*0.85)]
    test_idx = indices[int(n*0.85):]
    
    print(f"   Ø¢Ù…ÙˆØ²Ø´: {len(train_idx)} Ù†Ù…ÙˆÙ†Ù‡ ({len(train_idx)/n*100:.1f}%)")
    print(f"   Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {len(val_idx)} Ù†Ù…ÙˆÙ†Ù‡ ({len(val_idx)/n*100:.1f}%)")
    print(f"   Ø¢Ø²Ù…Ø§ÛŒØ´: {len(test_idx)} Ù†Ù…ÙˆÙ†Ù‡ ({len(test_idx)/n*100:.1f}%)")
    
    # Û´. Ø³Ø§Ø®Øª Ù…Ø¯Ù„
    print("\nğŸ—ï¸ Ù…Ø±Ø­Ù„Ù‡ Û²-Û´: Ø³Ø§Ø®Øª Ù…Ø¯Ù„ TabTransformer...")
    model = TabTransformer(
        num_categorical=X_cat.shape[1],
        num_continuous=X_cont.shape[1],
        categories=data_manager.categories,
        embedding_dim=32,
        num_heads=4,
        num_layers=3,
        mlp_hidden_dims=[128, 64],
        dropout=0.2,
        output_dim=1
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"   ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
    
    # Ûµ. Ø§ÛŒØ¬Ø§Ø¯ Trainer
    print("\nğŸ¤– Ù…Ø±Ø­Ù„Ù‡ Û²-Ûµ: Ø§ÛŒØ¬Ø§Ø¯ Trainer...")
    trainer = ExamTrainer(
        model=model, 
        model_type='tabtransformer', 
        model_name='tabtransformer_stage2',
        save_dir='models/stage2'
    )
    
    # Û¶. Ø§ÛŒØ¬Ø§Ø¯ DataLoader - âœ… Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø´Ú©Ù„ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ø­Ù„ Ú©Ø±Ø¯ÛŒÙ…
    print("\nğŸ“¦ Ù…Ø±Ø­Ù„Ù‡ Û²-Û¶: Ø§ÛŒØ¬Ø§Ø¯ DataLoader...")
    trainer.create_dataloaders(
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ùˆ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
        X_cat_train=X_cat[train_idx],
        X_cont_train=X_cont[train_idx],
        y_train=y[train_idx],
        
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ùˆ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
        X_cat_val=X_cat[val_idx],
        X_cont_val=X_cont[val_idx],
        y_val=y[val_idx],
        
        # Ø§Ù†Ø¯Ø§Ø²Ù‡ batch
        batch_size=64
    )
    
    # Û·. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
    print("\nğŸš€ Ù…Ø±Ø­Ù„Ù‡ Û²-Û·: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„...")
    trainer.train(
        epochs=50, 
        lr=0.001, 
        task_type='regression', 
        patience=10,
        verbose=True
    )
    
    # Û¸. Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¢Ù…ÙˆØ²Ø´
    print("\nğŸ“ˆ Ù…Ø±Ø­Ù„Ù‡ Û²-Û¸: Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø± Ø¢Ù…ÙˆØ²Ø´...")
    trainer.plot_history('plots/stage2/training_history.jpg')
    
    # Û¹. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
    print("\nğŸ“Š Ù…Ø±Ø­Ù„Ù‡ Û²-Û¹: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„...")
    results = trainer.evaluate(
        X_cat_test=X_cat[test_idx],
        X_cont_test=X_cont[test_idx],
        y_test=y[test_idx]
    )
    
    # Û±Û°. Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„
    print("\nğŸ’¾ Ù…Ø±Ø­Ù„Ù‡ Û²-Û±Û°: Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„...")
    torch.save({
        'model_state_dict': model.state_dict(),
        'config': {
            'num_categorical': X_cat.shape[1],
            'num_continuous': X_cont.shape[1],
            'categories': data_manager.categories,
            'embedding_dim': 32,
            'num_heads': 4,
            'num_layers': 3,
            'mlp_hidden_dims': [128, 64],
            'dropout': 0.2
        },
        'results': results,
        'history': trainer.history
    }, 'models/stage2/tabtransformer_model.pt')
    
    # Û±Û±. Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬
    print("\nğŸ’¾ Ù…Ø±Ø­Ù„Ù‡ Û²-Û±Û±: Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬...")
    results_df = pd.DataFrame([{
        'Model': 'TabTransformer',
        'RMSE': results['rmse'],
        'R2': results['r2'],
        'MAE': results.get('mae', 0),
        'Parameters': total_params
    }])
    results_df.to_csv('results/stage2/tabtransformer_results.csv', index=False, encoding='utf-8-sig')
    
    # Û±Û². Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´
    print("\nğŸ“ Ù…Ø±Ø­Ù„Ù‡ Û²-Û±Û²: Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´...")
    report = generate_report(results, trainer, data_manager, total_params)
    
    with open('reports/stage2_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("\n" + "="*70)
    print("âœ… Ù…Ø±Ø­Ù„Ù‡ Û² Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù…Ù„ Ø´Ø¯!")
    print("="*70)
    print(report)
    
    return results, trainer, report


def generate_report(results, trainer, data_manager, total_params):
    """
    Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø±Ø­Ù„Ù‡ Û²
    """
    report = []
    report.append("="*70)
    report.append("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø±Ø­Ù„Ù‡ Û²: Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ TabTransformer")
    report.append("="*70)
    report.append(f"ØªØ§Ø±ÛŒØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¹Ù…Ø§Ø±ÛŒ
    report.append("ğŸ—ï¸ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø¯Ù„:")
    report.append(f"  - ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ: {data_manager.X_cat.shape[1] if hasattr(data_manager, 'X_cat') else 0}")
    report.append(f"  - ØªØ¹Ø¯Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ: {data_manager.X_cont.shape[1] if hasattr(data_manager, 'X_cont') else 0}")
    report.append(f"  - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ: {data_manager.categories}")
    report.append(f"  - Ø§Ø¨Ø¹Ø§Ø¯ Embedding: 32")
    report.append(f"  - ØªØ¹Ø¯Ø§Ø¯ Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Transformer: 3")
    report.append(f"  - ØªØ¹Ø¯Ø§Ø¯ HeadÙ‡Ø§ÛŒ Attention: 4")
    report.append(f"  - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§: {total_params:,}")
    report.append("")
    
    # Ù†ØªØ§ÛŒØ¬ Ø¢Ù…ÙˆØ²Ø´
    report.append("ğŸ“ˆ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¢Ù…ÙˆØ²Ø´:")
    report.append(f"  - Ø¨Ù‡ØªØ±ÛŒÙ† Loss Ø¢Ù…ÙˆØ²Ø´: {min(trainer.history['train_loss']):.4f}")
    report.append(f"  - Ø¨Ù‡ØªØ±ÛŒÙ† Loss Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {min(trainer.history['val_loss']):.4f}")
    report.append(f"  - Ø¨Ù‡ØªØ±ÛŒÙ† RMSE Ø¢Ù…ÙˆØ²Ø´: {min(trainer.history['train_rmse']):.2f}")
    report.append(f"  - Ø¨Ù‡ØªØ±ÛŒÙ† RMSE Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ: {min(trainer.history['val_rmse']):.2f}")
    report.append("")
    
    # Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
    report.append("ğŸ¯ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ:")
    report.append(f"  - RMSE Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª: {results['rmse']:.2f}")
    report.append(f"  - MAE Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª: {results.get('mae', 0):.2f}")
    report.append(f"  - RÂ² Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª: {results['r2']:.4f}")
    report.append("")
    
    report.append("="*70)
    report.append("âœ… Ù¾Ø§ÛŒØ§Ù† Ú¯Ø²Ø§Ø±Ø´ Ù…Ø±Ø­Ù„Ù‡ Û²")
    report.append("="*70)
    
    return "\n".join(report)


if __name__ == "__main__":
    run_stage2()
